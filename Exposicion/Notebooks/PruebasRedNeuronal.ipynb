{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlpvQRKmg5mXeBIDoBGmAk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-oE_hMZrmin","executionInfo":{"status":"ok","timestamp":1747152189063,"user_tz":-120,"elapsed":17831,"user":{"displayName":"paco jones","userId":"00331554008511532701"}},"outputId":"01f4d394-1de1-4ca2-92e8-08cb06001ec1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Google Drive montado.\n"]}],"source":["# Montar Google Drive si los archivos están allí\n","from google.colab import drive\n","drive.mount('/content/drive')\n","print(\"Google Drive montado.\")"]},{"cell_type":"code","source":["# @title Celda de Configuración y Carga de Artefactos\n","\n","import os\n","import tensorflow as tf\n","import joblib\n","import pandas as pd\n","import numpy as np\n","import typing # Para anotaciones de tipo\n","import random\n","print(f\"TensorFlow Version: {tf.__version__}\")\n","print(f\"Keras Version (via TF): {tf.keras.__version__}\")\n","\n","# Esta es la ruta donde tienes tu carpeta mlp_v1 con los archivos\n","# Basado en tu código de guardado:\n","base_model_path = '/content/drive/MyDrive/Proyecto API/RedNeuronal/mlp_v1'\n","\n","\n","TF_SAVED_MODEL_PATH = base_model_path\n","OHE_PKL_FILENAME = \"ohe_mlp_cat.pkl\"\n","SCALER_PKL_FILENAME = \"scaler_mlp_num.pkl\"\n","OHE_PATH = os.path.join(base_model_path, OHE_PKL_FILENAME)\n","SCALER_PATH = os.path.join(base_model_path, SCALER_PKL_FILENAME)\n","\n","print(f\"\\nRuta al SavedModel: {TF_SAVED_MODEL_PATH}\")\n","print(f\"Ruta al OHE: {OHE_PATH}\")\n","print(f\"Ruta al Scaler: {SCALER_PATH}\")\n","\n","\n","# --- CONFIGURACIÓN DEL MODELO (Debe coincidir con la app de Streamlit) ---\n","_NUMERICAL_COLS_FOR_MODEL_PREPROCESSING = ['price_t0_log', 'days_diff']\n","_CATEGORICAL_COLS_FOR_MODEL_PREPROCESSING = [\n","    'artist_name', 'pokemon_name', 'rarity',\n","    'set_name', 'types', 'supertype', 'subtypes'\n","]\n","_MODEL_INPUT_TENSOR_KEY_NAME = 'inputs' # De saved_model_cli\n","_MODEL_OUTPUT_TENSOR_KEY_NAME = 'output_0' # De saved_model_cli\n","_TARGET_PREDICTED_IS_LOG_TRANSFORMED = True # Tu modelo predice log1p\n","DEFAULT_DAYS_DIFF_FOR_PREDICTION = 29.0    # El valor constante usado en el entrenamiento MLP\n","\n","\n","# --- Carga de Artefactos ---\n","def load_tf_model_as_layer(model_path):\n","    saved_model_pb_path = os.path.join(model_path, \"saved_model.pb\")\n","    if not os.path.exists(saved_model_pb_path):\n","        print(f\"ERROR: 'saved_model.pb' no encontrado en la ruta: {model_path}\")\n","        return None\n","    try:\n","        model_as_layer_obj = tf.keras.layers.TFSMLayer(model_path, call_endpoint='serving_default')\n","        print(f\"✅ SavedModel cargado exitosamente como TFSMLayer.\")\n","        try: print(f\"   Call Signature: {model_as_layer_obj._call_signature}\")\n","        except AttributeError: print(\"   No se pudo acceder a '_call_signature'.\")\n","        print(f\"   Clave de salida configurada: '{_MODEL_OUTPUT_TENSOR_KEY_NAME}'.\")\n","        return model_as_layer_obj\n","    except Exception as e:\n","        print(f\"❌ ERROR al cargar SavedModel como TFSMLayer desde {model_path}: {e}\")\n","        return None\n","\n","def load_preprocessor(file_path, preprocessor_name=\"Preprocessor\"):\n","    if not os.path.exists(file_path):\n","        print(f\"❌ ERROR: Archivo '{preprocessor_name}' no encontrado en: {file_path}\")\n","        return None\n","    try:\n","        preprocessor = joblib.load(file_path)\n","        print(f\"✅ {preprocessor_name} cargado exitosamente desde: {file_path}\")\n","        return preprocessor\n","    except Exception as e:\n","        print(f\"❌ ERROR al cargar {preprocessor_name} desde {file_path}: {e}\")\n","        return None\n","\n","# Cargar los artefactos\n","print(\"\\nCargando artefactos del modelo...\")\n","local_tf_model_layer = load_tf_model_as_layer(TF_SAVED_MODEL_PATH)\n","ohe_local_preprocessor = load_preprocessor(OHE_PATH, \"OneHotEncoder\")\n","scaler_local_preprocessor = load_preprocessor(SCALER_PATH, \"ScalerNumérico\")\n","\n","if local_tf_model_layer and ohe_local_preprocessor and scaler_local_preprocessor:\n","    print(\"\\n✅ Todos los artefactos del modelo cargados correctamente.\")\n","else:\n","    print(\"\\n❌ Error: No se pudieron cargar todos los artefactos. No se podrán realizar pruebas.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aE9O92MEr_wB","executionInfo":{"status":"ok","timestamp":1747143535853,"user_tz":-120,"elapsed":116,"user":{"displayName":"paco jones","userId":"00331554008511532701"}},"outputId":"bf704e59-2684-4c43-aa50-37dda9b7d39d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow Version: 2.18.0\n","Keras Version (via TF): 3.8.0\n","\n","Ruta al SavedModel: /content/drive/MyDrive/Proyecto API/RedNeuronal/mlp_v1\n","Ruta al OHE: /content/drive/MyDrive/Proyecto API/RedNeuronal/mlp_v1/ohe_mlp_cat.pkl\n","Ruta al Scaler: /content/drive/MyDrive/Proyecto API/RedNeuronal/mlp_v1/scaler_mlp_num.pkl\n","\n","Cargando artefactos del modelo...\n","✅ SavedModel cargado exitosamente como TFSMLayer.\n","   Call Signature: (inputs, training=False, **kwargs)\n","   Clave de salida configurada: 'output_0'.\n","✅ OneHotEncoder cargado exitosamente desde: /content/drive/MyDrive/Proyecto API/RedNeuronal/mlp_v1/ohe_mlp_cat.pkl\n","✅ ScalerNumérico cargado exitosamente desde: /content/drive/MyDrive/Proyecto API/RedNeuronal/mlp_v1/scaler_mlp_num.pkl\n","\n","✅ Todos los artefactos del modelo cargados correctamente.\n"]}]},{"cell_type":"code","source":["# @title Celda de la Función de Predicción\n","\n","def predict_price_with_local_tf_layer(\n","    model_layer: tf.keras.layers.TFSMLayer,\n","    ohe: typing.Any, # OneHotEncoder\n","    scaler: typing.Any, # StandardScaler\n","    card_data_series: pd.Series # Una Series de Pandas con los datos de la carta\n",") -> float | None:\n","    print(f\"\\n--- Iniciando predicción para carta ID: {card_data_series.get('id', 'N/A')} ---\")\n","\n","    if not model_layer or not ohe or not scaler:\n","        print(\"ERROR: Modelo TFSMLayer o preprocesadores no disponibles.\")\n","        return None\n","\n","    try:\n","        # --- PASO 1: Preparar DataFrame de entrada para preprocesamiento ---\n","        # Replicamos exactamente la lógica de mapeo desde los datos de entrada\n","        data_for_preprocessing_df_dict = {}\n","\n","        # Columnas Numéricas\n","        current_price = card_data_series.get('price')\n","        if pd.notna(current_price) and current_price > 0:\n","            data_for_preprocessing_df_dict['price_t0_log'] = np.log1p(current_price)\n","        else:\n","            data_for_preprocessing_df_dict['price_t0_log'] = np.log1p(0)\n","            print(f\"WARNING: Precio actual no válido ('{current_price}') para 'price_t0_log', usando np.log1p(0).\")\n","        data_for_preprocessing_df_dict['days_diff'] = float(DEFAULT_DAYS_DIFF_FOR_PREDICTION)\n","\n","\n","        # Columnas Categóricas\n","        data_for_preprocessing_df_dict['artist_name'] = str(card_data_series.get('artist', 'Unknown_Artist'))\n","        data_for_preprocessing_df_dict['pokemon_name'] = str(card_data_series.get('pokemon_name', 'Unknown_Pokemon'))\n","        data_for_preprocessing_df_dict['rarity'] = str(card_data_series.get('rarity', 'Unknown_Rarity'))\n","        data_for_preprocessing_df_dict['set_name'] = str(card_data_series.get('set_name', 'Unknown_Set'))\n","        data_for_preprocessing_df_dict['supertype'] = str(card_data_series.get('supertype', 'Unknown_Supertype'))\n","\n","        types_val = card_data_series.get('types')\n","        if isinstance(types_val, list) and types_val: data_for_preprocessing_df_dict['types'] = str(types_val[0]) if pd.notna(types_val[0]) else 'Unknown_Type'\n","        elif pd.notna(types_val): data_for_preprocessing_df_dict['types'] = str(types_val)\n","        else: data_for_preprocessing_df_dict['types'] = 'Unknown_Type'\n","\n","        subtypes_val = card_data_series.get('subtypes')\n","        if isinstance(subtypes_val, list) and subtypes_val:\n","            cleaned_subtypes = [str(s) for s in subtypes_val if pd.notna(s)]\n","            data_for_preprocessing_df_dict['subtypes'] = ', '.join(sorted(list(set(cleaned_subtypes)))) if cleaned_subtypes else 'None'\n","        elif pd.notna(subtypes_val): data_for_preprocessing_df_dict['subtypes'] = str(subtypes_val)\n","        else: data_for_preprocessing_df_dict['subtypes'] = 'None'\n","\n","\n","        current_input_df_for_preprocessing = pd.DataFrame([data_for_preprocessing_df_dict])\n","        ordered_cols_for_df = _NUMERICAL_COLS_FOR_MODEL_PREPROCESSING + _CATEGORICAL_COLS_FOR_MODEL_PREPROCESSING\n","        try:\n","            current_input_df_for_preprocessing = current_input_df_for_preprocessing[ordered_cols_for_df]\n","        except KeyError as e_key:\n","            missing_keys_in_df = [col for col in ordered_cols_for_df if col not in current_input_df_for_preprocessing.columns]\n","            print(f\"ERROR: Error al ordenar columnas para preprocesamiento. Faltan: {missing_keys_in_df}. Error: {e_key}\")\n","            return None\n","        print(f\"INFO: DataFrame para preprocesamiento (1 fila): {current_input_df_for_preprocessing.shape}. Cols: {list(current_input_df_for_preprocessing.columns)}\")\n","        print(f\"DEBUG: Valores: {current_input_df_for_preprocessing.iloc[0].to_dict()}\")\n","\n","\n","        # --- PASO 2: Aplicar preprocesamiento (Scaler y OneHotEncoder) ---\n","        processed_feature_parts = []\n","        if _NUMERICAL_COLS_FOR_MODEL_PREPROCESSING:\n","            num_df_slice = current_input_df_for_preprocessing[_NUMERICAL_COLS_FOR_MODEL_PREPROCESSING]\n","            if num_df_slice.isnull().values.any():\n","                print(f\"WARNING: NaNs ANTES de escalar: {num_df_slice.isnull().sum().to_dict()}. Imputando con 0.\")\n","                num_df_slice = num_df_slice.fillna(0)\n","            numerical_features_scaled_array = scaler.transform(num_df_slice)\n","            processed_feature_parts.append(numerical_features_scaled_array)\n","            print(f\"INFO: Numéricas escaladas (shape): {numerical_features_scaled_array.shape}\")\n","\n","        if _CATEGORICAL_COLS_FOR_MODEL_PREPROCESSING:\n","            cat_df_slice = current_input_df_for_preprocessing[_CATEGORICAL_COLS_FOR_MODEL_PREPROCESSING].astype(str)\n","            categorical_features_encoded_dense_array = ohe.transform(cat_df_slice)\n","            processed_feature_parts.append(categorical_features_encoded_dense_array)\n","            print(f\"INFO: Categóricas codificadas (shape): {categorical_features_encoded_dense_array.shape}\")\n","\n","        if not processed_feature_parts:\n","            print(\"ERROR: No se procesaron características.\")\n","            return None\n","\n","        # --- PASO 3: Combinar ---\n","        final_input_array_for_model = np.concatenate(processed_feature_parts, axis=1)\n","        print(f\"INFO: Array final para modelo (shape): {final_input_array_for_model.shape}\")\n","\n","        EXPECTED_NUM_FEATURES = 4865 # Confirmado por saved_model_cli\n","        if final_input_array_for_model.shape[1] != EXPECTED_NUM_FEATURES:\n","            print(f\"ERROR: ¡¡¡DESAJUSTE DE SHAPE EN LA ENTRADA DEL MODELO!!!\")\n","            print(f\"    Modelo espera: {EXPECTED_NUM_FEATURES} características.\")\n","            print(f\"    Array preprocesado tiene: {final_input_array_for_model.shape[1]} características.\")\n","            if 'numerical_features_scaled_array' in locals(): print(f\"    Shape numéricas escaladas: {numerical_features_scaled_array.shape}\")\n","            if 'categorical_features_encoded_dense_array' in locals(): print(f\"    Shape categóricas OHE: {categorical_features_encoded_dense_array.shape}\")\n","            return None\n","\n","        # --- PASO 4: Predicción ---\n","        final_input_tensor_for_model = tf.convert_to_tensor(final_input_array_for_model, dtype=tf.float32)\n","        print(f\"INFO: Tensor de entrada para TFSMLayer (shape): {final_input_tensor_for_model.shape}, dtype: {final_input_tensor_for_model.dtype}\")\n","\n","        model_input_feed_dict = {_MODEL_INPUT_TENSOR_KEY_NAME: final_input_tensor_for_model}\n","        print(f\"INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='{_MODEL_INPUT_TENSOR_KEY_NAME}'\")\n","        raw_prediction_output = model_layer(**model_input_feed_dict)\n","\n","        print(f\"INFO: Salida cruda de TFSMLayer (tipo {type(raw_prediction_output)}): {raw_prediction_output}\")\n","\n","        if not isinstance(raw_prediction_output, dict):\n","            if tf.is_tensor(raw_prediction_output): predicted_value_tensor = raw_prediction_output\n","            else:\n","                print(f\"ERROR: Salida de TFSMLayer no es ni dict ni tensor, es {type(raw_prediction_output)}.\")\n","                return None\n","        elif not raw_prediction_output:\n","            print(\"ERROR: Dict de salida vacío.\")\n","            return None\n","        elif _MODEL_OUTPUT_TENSOR_KEY_NAME not in raw_prediction_output:\n","            available_keys = list(raw_prediction_output.keys())\n","            print(f\"ERROR: Clave '{_MODEL_OUTPUT_TENSOR_KEY_NAME}' NO en dict. Claves: {available_keys}\")\n","            return None\n","        else: predicted_value_tensor = raw_prediction_output[_MODEL_OUTPUT_TENSOR_KEY_NAME]\n","        print(f\"INFO: Tensor (clave '{_MODEL_OUTPUT_TENSOR_KEY_NAME}' si dict). Shape: {predicted_value_tensor.shape}\")\n","\n","        if predicted_value_tensor.shape == (1, 1) or predicted_value_tensor.shape == (1,):\n","            predicted_value_numeric = predicted_value_tensor.numpy()[0][0] if len(predicted_value_tensor.shape) == 2 else predicted_value_tensor.numpy()[0]\n","        else:\n","            print(f\"ERROR: Shape tensor predicción: {predicted_value_tensor.shape}. Esperada (1,1) o (1,).\")\n","            return None\n","        print(f\"INFO: Valor numérico extraído: {predicted_value_numeric}\")\n","\n","        # --- PASO 5: Postprocesar ---\n","        if _TARGET_PREDICTED_IS_LOG_TRANSFORMED:\n","             final_predicted_price = np.expm1(predicted_value_numeric) # Usar expm1\n","        else: final_predicted_price = predicted_value_numeric\n","        print(f\"INFO: Predicción final: {final_predicted_price}\")\n","\n","        return float(final_predicted_price)\n","\n","    except Exception as e:\n","        print(f\"ERROR: Excepción en predicción: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        return None"],"metadata":{"id":"hLwg9I_csP9T","executionInfo":{"status":"ok","timestamp":1747143538266,"user_tz":-120,"elapsed":15,"user":{"displayName":"paco jones","userId":"00331554008511532701"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# @title Celda de Prueba de Predicción con 10 Cartas Aleatorias\n","\n","# --- PASO 1: Cargar o Usar all_card_metadata_df ---\n","# (Asegúrate que all_card_metadata_df esté cargado y contenga 'name' y otras columnas de metadatos)\n","if 'all_card_metadata_df' not in locals() or all_card_metadata_df.empty:\n","    print(\"ERROR: El DataFrame 'all_card_metadata_df' no está cargado o está vacío.\")\n","    print(\"Por favor, asegúrate de cargar tus metadatos antes de ejecutar esta celda.\")\n","    # Aquí podrías añadir el código para cargar all_card_metadata_df si es necesario\n","    # Ejemplo (si tienes bq_client configurado en Colab y la función get_card_metadata_with_base_names):\n","    # print(\"Intentando cargar all_card_metadata_df desde BigQuery...\")\n","    # all_card_metadata_df = get_card_metadata_with_base_names(bq_client)\n","    # if all_card_metadata_df.empty:\n","    #     print(\"Fallo al cargar metadatos desde BQ para la prueba.\")\n","    # else:\n","    #     print(f\"Metadatos cargados desde BQ para la prueba: {len(all_card_metadata_df)} filas.\")\n","\n","else: # all_card_metadata_df está disponible\n","    print(f\"\\n--- Ejecutando pruebas de predicción con 10 cartas aleatorias ---\")\n","    print(f\"Metadatos disponibles: {len(all_card_metadata_df)} cartas.\")\n","\n","    # --- PASO 2: Seleccionar 10 cartas aleatorias con imagen ---\n","    cards_with_image = all_card_metadata_df[\n","        pd.notna(all_card_metadata_df['images_large']) & (all_card_metadata_df['images_large'] != '')\n","    ].copy()\n","\n","    if cards_with_image.empty:\n","        print(\"ERROR: No se encontraron cartas con URLs de imagen en los metadatos.\")\n","    else:\n","        num_cards_to_sample = min(10, len(cards_with_image))\n","        print(f\"Seleccionando {num_cards_to_sample} cartas aleatorias con imagen.\")\n","        sample_indices = random.sample(cards_with_image.index.tolist(), num_cards_to_sample)\n","\n","        # Crear el DataFrame de prueba usando las columnas de all_card_metadata_df\n","        # Y asegurando que los nombres coincidan con lo que espera card_data_series\n","        # en la función de predicción.\n","        test_cards_df = cards_with_image.loc[sample_indices].copy()\n","        test_cards_df.rename(columns={'name': 'pokemon_name_original_meta'}, inplace=True) # Renombrar 'name' para evitar confusión si hay otra\n","                                                                                     # columna 'pokemon_name' que se use para el OHE\n","\n","        # Simular precios (o cargar precios reales si los tienes)\n","        test_cards_df['price'] = np.random.uniform(1.0, 50.0, size=len(test_cards_df)) # Precios más realistas para prueba\n","        print(\"\\nDEBUG: Precios simulados (rango 1-50) añadidos para prueba.\")\n","        print(\"DEBUG: Columnas en test_cards_df:\", test_cards_df.columns.tolist())\n","\n","\n","        # --- PASO 3: Ejecutar la predicción para cada carta ---\n","        print(\"\\n--- Ejecutando predicciones ---\")\n","        predictions = {}\n","\n","        if local_tf_model_layer and ohe_local_preprocessor and scaler_local_preprocessor:\n","            for index, card_row in test_cards_df.iterrows():\n","                # Crear la card_data_series para la función de predicción\n","                # Asegúrate de que las claves aquí coincidan con lo que card_data_series.get() espera\n","                # dentro de predict_price_with_local_tf_layer\n","\n","                # Mapeo explícito para asegurar que los nombres son los correctos\n","                # para la función de predicción.\n","                input_series_data = {\n","                    'id': card_row.get('id'),\n","                    'pokemon_name': card_row.get('pokemon_name_original_meta'), # Usar el nombre original de la carta\n","                    'supertype': card_row.get('supertype'),\n","                    'subtypes': card_row.get('subtypes'),\n","                    'types': card_row.get('types'),\n","                    'rarity': card_row.get('rarity'),\n","                    'set_name': card_row.get('set_name'),\n","                    'artist': card_row.get('artist'), # 'artist' es el nombre en all_card_metadata_df\n","                    'price': card_row.get('price')\n","                    # Añade otras columnas si tu función de predicción las espera de card_data_series\n","                }\n","                card_data_series_for_prediction = pd.Series(input_series_data)\n","\n","                card_name_display = card_row.get('pokemon_name_original_meta')\n","                current_price = card_row.get('price')\n","\n","                print(f\"\\nPrediciendo para: {card_name_display} (ID: {card_row.get('id')}, Precio Actual Sim.: {current_price:.2f}€)\")\n","                print(f\"DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = {card_data_series_for_prediction.get('pokemon_name')}\")\n","\n","\n","                if pd.notna(current_price):\n","                    predicted_price = predict_price_with_local_tf_layer(\n","                        local_tf_model_layer,\n","                        ohe_local_preprocessor,\n","                        scaler_local_preprocessor,\n","                        card_data_series_for_prediction # Usar la Series preparada\n","                    )\n","\n","                    if predicted_price is not None:\n","                        predictions[card_row.get('id')] = {\n","                            'name': card_name_display,\n","                            'current_price': current_price,\n","                            'predicted_price': predicted_price,\n","                            'delta': predicted_price - current_price\n","                        }\n","                        print(f\"INFO: Predicción completada. Predicho: {predicted_price:.2f}€\")\n","                    else:\n","                        print(f\"WARNING: Falló la predicción para {card_name_display} ({card_row.get('id')}).\")\n","                else:\n","                    print(f\"INFO: Saltando predicción para {card_name_display} ({card_row.get('id')}) - Precio actual no disponible.\")\n","\n","            # --- PASO 4: Mostrar un resumen de los resultados ---\n","            print(\"\\n--- Resumen de Predicciones ---\")\n","            if predictions:\n","                summary_df = pd.DataFrame.from_dict(predictions, orient='index')\n","                print(summary_df[['name', 'current_price', 'predicted_price', 'delta']].to_string())\n","            else:\n","                print(\"\\nNo se realizaron predicciones exitosas.\")\n","        else:\n","            print(\"\\n❌ Error: Los artefactos del modelo no se cargaron. No se pueden realizar predicciones.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjMtOtMNsU9j","executionInfo":{"status":"ok","timestamp":1747143542517,"user_tz":-120,"elapsed":352,"user":{"displayName":"paco jones","userId":"00331554008511532701"}},"outputId":"e1b94701-2162-4865-d8d6-6d642e976752"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Ejecutando pruebas de predicción con 10 cartas aleatorias ---\n","Metadatos disponibles: 18876 cartas.\n","Seleccionando 10 cartas aleatorias con imagen.\n","\n","DEBUG: Precios simulados (rango 1-50) añadidos para prueba.\n","DEBUG: Columnas en test_cards_df: ['id', 'pokemon_name_original_meta', 'supertype', 'subtypes', 'rarity', 'set_id', 'set_name', 'number', 'artist', 'types', 'ancientTrait', 'images_small', 'images_large', 'cardmarket_url', 'cardmarket_updatedAt', 'tcgplayer_url', 'tcgplayer_updatedAt', 'price']\n","\n","--- Ejecutando predicciones ---\n","\n","Prediciendo para: M Mewtwo-EX (ID: xy8-63, Precio Actual Sim.: 8.37€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = M Mewtwo-EX\n","\n","--- Iniciando predicción para carta ID: xy8-63 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 2.238026713912398, 'days_diff': 29.0, 'artist_name': '5ban Graphics', 'pokemon_name': 'M Mewtwo-EX', 'rarity': 'Rare Holo EX', 'set_name': 'BREAKthrough', 'types': 'Psychic', 'supertype': 'Pokémon', 'subtypes': 'MEGA, EX'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.8501033]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 1.8501032590866089\n","INFO: Predicción final: 5.360476493835449\n","INFO: Predicción completada. Predicho: 5.36€\n","\n","Prediciendo para: Shaymin V (ID: swsh9-13, Precio Actual Sim.: 21.55€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Shaymin V\n","\n","--- Iniciando predicción para carta ID: swsh9-13 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 3.115539138442539, 'days_diff': 29.0, 'artist_name': 'Satoshi Shirai', 'pokemon_name': 'Shaymin V', 'rarity': 'Rare Holo V', 'set_name': 'Brilliant Stars', 'types': 'Grass', 'supertype': 'Pokémon', 'subtypes': 'Basic, V'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.1792932]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 2.179293155670166\n","INFO: Predicción final: 7.840055465698242\n","INFO: Predicción completada. Predicho: 7.84€\n","\n","Prediciendo para: Lost City (ID: swsh11-161, Precio Actual Sim.: 19.83€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Lost City\n","\n","--- Iniciando predicción para carta ID: swsh11-161 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 3.036198358335783, 'days_diff': 29.0, 'artist_name': 'AYUMI ODASHIMA', 'pokemon_name': 'Lost City', 'rarity': 'Uncommon', 'set_name': 'Lost Origin', 'types': 'Trainer', 'supertype': 'Trainer', 'subtypes': 'Stadium'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.4146361]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 1.4146361351013184\n","INFO: Predicción final: 3.1149888038635254\n","INFO: Predicción completada. Predicho: 3.11€\n","\n","Prediciendo para: Yell Horn (ID: swsh3-173, Precio Actual Sim.: 2.55€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Yell Horn\n","\n","--- Iniciando predicción para carta ID: swsh3-173 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 1.2660536399930842, 'days_diff': 29.0, 'artist_name': '5ban Graphics', 'pokemon_name': 'Yell Horn', 'rarity': 'Uncommon', 'set_name': 'Darkness Ablaze', 'types': 'Trainer', 'supertype': 'Trainer', 'subtypes': 'Item'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.52679294]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 0.5267929434776306\n","INFO: Predicción final: 0.6934924721717834\n","INFO: Predicción completada. Predicho: 0.69€\n","\n","Prediciendo para: Talonflame (ID: swsh12-29, Precio Actual Sim.: 1.33€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Talonflame\n","\n","--- Iniciando predicción para carta ID: swsh12-29 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 0.8451676266206778, 'days_diff': 29.0, 'artist_name': 'KEIICHIRO ITO', 'pokemon_name': 'Talonflame', 'rarity': 'Rare', 'set_name': 'Silver Tempest', 'types': 'Fire', 'supertype': 'Pokémon', 'subtypes': 'Stage 2'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.3613918]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 0.3613918125629425\n","INFO: Predicción final: 0.4353257417678833\n","INFO: Predicción completada. Predicho: 0.44€\n","\n","Prediciendo para: Darkness Energy (ID: ecard1-158, Precio Actual Sim.: 31.53€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Darkness Energy\n","\n","--- Iniciando predicción para carta ID: ecard1-158 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 3.4822328866451047, 'days_diff': 29.0, 'artist_name': 'Milky Isobe', 'pokemon_name': 'Darkness Energy', 'rarity': 'Rare', 'set_name': 'Expedition Base Set', 'types': 'Energy', 'supertype': 'Energy', 'subtypes': 'Special'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.7699091]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 2.769909143447876\n","INFO: Predicción final: 14.957183837890625\n","INFO: Predicción completada. Predicho: 14.96€\n","\n","Prediciendo para: Hisuian Lilligant V (ID: swsh10-162, Precio Actual Sim.: 39.58€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Hisuian Lilligant V\n","\n","--- Iniciando predicción para carta ID: swsh10-162 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 3.7033897616770144, 'days_diff': 29.0, 'artist_name': '5ban Graphics', 'pokemon_name': 'Hisuian Lilligant V', 'rarity': 'Rare Ultra', 'set_name': 'Astral Radiance', 'types': 'Grass', 'supertype': 'Pokémon', 'subtypes': 'Basic, V'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.5934744]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 2.5934743881225586\n","INFO: Predicción final: 12.376165390014648\n","INFO: Predicción completada. Predicho: 12.38€\n","\n","Prediciendo para: Recycle Energy (ID: neo1-105, Precio Actual Sim.: 38.46€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Recycle Energy\n","\n","--- Iniciando predicción para carta ID: neo1-105 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 3.6753076374706244, 'days_diff': 29.0, 'artist_name': 'Hideki Kazama', 'pokemon_name': 'Recycle Energy', 'rarity': 'Rare', 'set_name': 'Neo Genesis', 'types': 'Energy', 'supertype': 'Energy', 'subtypes': 'Special'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.7653096]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 2.7653095722198486\n","INFO: Predicción final: 14.883956909179688\n","INFO: Predicción completada. Predicho: 14.88€\n","\n","Prediciendo para: Doublade (ID: swsh2-134, Precio Actual Sim.: 4.31€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Doublade\n","\n","--- Iniciando predicción para carta ID: swsh2-134 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 1.6688959817910871, 'days_diff': 29.0, 'artist_name': 'Aya Kusube', 'pokemon_name': 'Doublade', 'rarity': 'Uncommon', 'set_name': 'Rebel Clash', 'types': 'Metal', 'supertype': 'Pokémon', 'subtypes': 'Stage 1'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.0831176]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 1.0831176042556763\n","INFO: Predicción final: 1.9538742303848267\n","INFO: Predicción completada. Predicho: 1.95€\n","\n","Prediciendo para: Dragonite VSTAR (ID: swshp-SWSH236, Precio Actual Sim.: 29.92€)\n","DEBUG (Pre-Predicción): card_data_series_for_prediction['pokemon_name'] = Dragonite VSTAR\n","\n","--- Iniciando predicción para carta ID: swshp-SWSH236 ---\n","INFO: DataFrame para preprocesamiento (1 fila): (1, 9). Cols: ['price_t0_log', 'days_diff', 'artist_name', 'pokemon_name', 'rarity', 'set_name', 'types', 'supertype', 'subtypes']\n","DEBUG: Valores: {'price_t0_log': 3.431252750624827, 'days_diff': 29.0, 'artist_name': 'PLANETA Mochizuki', 'pokemon_name': 'Dragonite VSTAR', 'rarity': 'Promo', 'set_name': 'SWSH Black Star Promos', 'types': 'Dragon', 'supertype': 'Pokémon', 'subtypes': 'VSTAR'}\n","INFO: Numéricas escaladas (shape): (1, 2)\n","INFO: Categóricas codificadas (shape): (1, 4863)\n","INFO: Array final para modelo (shape): (1, 4865)\n","INFO: Tensor de entrada para TFSMLayer (shape): (1, 4865), dtype: <dtype: 'float32'>\n","INFO: Llamando a TFSMLayer con diccionario desempaquetado: Clave='inputs'\n","INFO: Salida cruda de TFSMLayer (tipo <class 'dict'>): {'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.6666262]], dtype=float32)>}\n","INFO: Tensor (clave 'output_0' si dict). Shape: (1, 1)\n","INFO: Valor numérico extraído: 2.666626214981079\n","INFO: Predicción final: 13.39133358001709\n","INFO: Predicción completada. Predicho: 13.39€\n","\n","--- Resumen de Predicciones ---\n","                              name  current_price  predicted_price      delta\n","xy8-63                 M Mewtwo-EX       8.374814         5.360476  -3.014337\n","swsh9-13                 Shaymin V      21.545582         7.840055 -13.705527\n","swsh11-161               Lost City      19.825920         3.114989 -16.710931\n","swsh3-173                Yell Horn       2.546828         0.693492  -1.853335\n","swsh12-29               Talonflame       1.328368         0.435326  -0.893042\n","ecard1-158         Darkness Energy      31.532282        14.957184 -16.575098\n","swsh10-162     Hisuian Lilligant V      39.584644        12.376165 -27.208478\n","neo1-105            Recycle Energy      38.460795        14.883957 -23.576838\n","swsh2-134                 Doublade       4.306306         1.953874  -2.352432\n","swshp-SWSH236      Dragonite VSTAR      29.915348        13.391334 -16.524014\n"]}]},{"cell_type":"code","source":["# @title Celda 1: Carga de Pipelines LightGBM y Threshold JSON\n","\n","import json\n","import joblib\n","import pandas as pd\n","import numpy as np\n","import os\n","from google.colab import drive\n","import typing\n","\n","\n","# --- RUTAS (¡¡¡AJUSTA ESTAS!!!) ---\n","BASE_PROJECT_PATH = '/content/drive/MyDrive/Proyecto API/Modelos' # Carpeta que contiene High/, Low/, threshold.json\n","\n","# ASUME que guardaste el 'best_high' si hiciste RandomizedSearchCV, o 'pipe_high' si no.\n","# Si guardaste 'best_high', el archivo .pkl debe contener ese objeto.\n","MODEL_HIGH_PKL_PATH = os.path.join('/content/drive/MyDrive/Proyecto API/Modelos/High/modelo_pipe_high.pkl')\n","MODEL_LOW_PKL_PATH = os.path.join('/content/drive/MyDrive/Proyecto API/Modelos/Low/modelo_pipe_low.pkl')\n","THRESHOLD_JSON_PATH = os.path.join('/content/drive/MyDrive/Proyecto API/Modelos/threshold.json')\n","\n","# --- Cargar Pipelines .pkl ---\n","pipeline_high_loaded = None\n","pipeline_low_loaded = None\n","\n","try:\n","    if os.path.exists(MODEL_HIGH_PKL_PATH):\n","        pipeline_high_loaded = joblib.load(MODEL_HIGH_PKL_PATH)\n","        print(f\"✅ Pipeline High (.pkl) cargado desde: {MODEL_HIGH_PKL_PATH}\")\n","        print(f\"   Tipo de Pipeline High: {type(pipeline_high_loaded)}\")\n","        if hasattr(pipeline_high_loaded, 'steps'): print(f\"   Pasos del Pipeline High: {pipeline_high_loaded.steps}\")\n","    else: print(f\"AVISO: Archivo de Pipeline High no encontrado en {MODEL_HIGH_PKL_PATH}\")\n","except Exception as e: print(f\"❌ ERROR al cargar Pipeline High (.pkl): {e}\")\n","\n","try:\n","    if os.path.exists(MODEL_LOW_PKL_PATH):\n","        pipeline_low_loaded = joblib.load(MODEL_LOW_PKL_PATH)\n","        print(f\"✅ Pipeline Low (.pkl) cargado desde: {MODEL_LOW_PKL_PATH}\")\n","        print(f\"   Tipo de Pipeline Low: {type(pipeline_low_loaded)}\")\n","        if hasattr(pipeline_low_loaded, 'steps'): print(f\"   Pasos del Pipeline Low: {pipeline_low_loaded.steps}\")\n","    else: print(f\"AVISO: Archivo de Pipeline Low no encontrado en {MODEL_LOW_PKL_PATH}\")\n","except Exception as e: print(f\"❌ ERROR al cargar Pipeline Low (.pkl): {e}\")\n","\n","\n","# --- Cargar Threshold JSON ---\n","try:\n","    if os.path.exists(THRESHOLD_JSON_PATH):\n","        with open(THRESHOLD_JSON_PATH, 'r') as f:\n","            threshold_config_loaded = json.load(f)\n","        print(f\"✅ Threshold JSON cargado: {threshold_config_loaded}\")\n","    else:\n","        print(f\"AVISO: Archivo Threshold JSON no encontrado en {THRESHOLD_JSON_PATH}\")\n","        threshold_config_loaded = {\"threshold\": 30.0} # Default si no se encuentra\n","except Exception as e:\n","    print(f\"❌ ERROR al cargar Threshold JSON: {e}\")\n","    threshold_config_loaded = {\"threshold\": 30.0}\n","\n","# --- CONFIGURACIÓN BASADA EN TU SCRIPT DE ENTRENAMIENTO ---\n","# Columnas que esperan los pipelines en el DataFrame de entrada\n","NUMERIC_FEATURES_INPUT = ['cm_avg1', 'cm_avg7', 'cm_avg30', 'cm_trendPrice']\n","CATEGORICAL_FEATURES_INPUT = ['rarity', 'supertype', 'subtypes', 'types', 'set_name']\n","ALL_INPUT_COLS_FOR_PIPELINES = NUMERIC_FEATURES_INPUT + CATEGORICAL_FEATURES_INPUT\n","\n","TARGET_IS_LOG_TRANSFORMED = True # Ambos pipelines predicen log1p\n","\n","if pipeline_high_loaded or pipeline_low_loaded:\n","    print(\"\\n✅ Al menos un pipeline cargado.\")\n","else:\n","    print(\"\\n❌ Error: Ningún pipeline (High o Low) pudo ser cargado. No se podrán realizar pruebas.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9U7SAcOtYu4S","executionInfo":{"status":"ok","timestamp":1747155147247,"user_tz":-120,"elapsed":56,"user":{"displayName":"paco jones","userId":"00331554008511532701"}},"outputId":"1bbc2889-709c-4292-f1bb-9966c4855ccf"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Pipeline High (.pkl) cargado desde: /content/drive/MyDrive/Proyecto API/Modelos/High/modelo_pipe_high.pkl\n","   Tipo de Pipeline High: <class 'sklearn.pipeline.Pipeline'>\n","   Pasos del Pipeline High: [('preprocessor', ColumnTransformer(transformers=[('num', StandardScaler(),\n","                                 ['cm_avg1', 'cm_avg7', 'cm_avg30',\n","                                  'cm_trendPrice']),\n","                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n","                                 ['rarity', 'supertype', 'subtypes', 'types',\n","                                  'set_name'])])), ('regressor', LGBMRegressor(force_row_wise=True, n_estimators=200, objective='mae',\n","              random_state=42, verbosity=-1))]\n","✅ Pipeline Low (.pkl) cargado desde: /content/drive/MyDrive/Proyecto API/Modelos/Low/modelo_pipe_low.pkl\n","   Tipo de Pipeline Low: <class 'sklearn.pipeline.Pipeline'>\n","   Pasos del Pipeline Low: [('preprocessor', ColumnTransformer(remainder='passthrough',\n","                  transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n","                                 ['rarity', 'supertype', 'subtypes', 'types',\n","                                  'set_name'])])), ('regressor', LGBMRegressor(force_row_wise=True, objective='mae', random_state=42,\n","              verbosity=-1))]\n","✅ Threshold JSON cargado: {'threshold': 30.0}\n","\n","✅ Al menos un pipeline cargado.\n"]}]},{"cell_type":"code","source":["# @title Celda 2: Lógica de Decisión y Predicción con Pipelines .pkl\n","\n","import pandas as pd # Asegurar que pandas esté importado en esta celda si se ejecuta de forma aislada\n","import numpy as np  # Asegurar que numpy esté importado\n","import typing       # Asegurar que typing esté importado\n","\n","def get_prediction_with_lgbm_pipelines(\n","    input_df_row: pd.DataFrame,\n","    config: dict,\n","    # Estas variables vienen del scope global del notebook (definidas en Celda 1)\n","    pipe_high, # Debería ser pipeline_high_loaded\n","    pipe_low   # Debería ser pipeline_low_loaded\n",") -> typing.Tuple[typing.Optional[float], str]:\n","\n","    chosen_pipeline_name = \"None\"\n","    final_prediction = None\n","\n","    # Verificar si los pipelines fueron cargados (vienen de Celda 1)\n","    if pipe_high is None and pipe_low is None:\n","        print(\"ERROR en get_prediction: Ningún pipeline (High o Low) está cargado.\")\n","        return None, \"Error_No_Pipelines\"\n","\n","    try:\n","        # INPUT_COLS_FOR_PIPELINES también debe estar disponible (definida en Celda 1)\n","        X_new_predict = input_df_row[INPUT_COLS_FOR_PIPELINES]\n","    except NameError:\n","        print(\"ERROR en get_prediction: INPUT_COLS_FOR_PIPELINES no definida. Ejecuta la Celda 1.\")\n","        return None, \"Error_Config_Missing\"\n","    except KeyError as e:\n","        print(f\"ERROR en get_prediction: Faltan columnas en input_df_row: {e}\")\n","        return None, \"Error_Input_Cols\"\n","\n","    cm_avg7_value_for_decision = X_new_predict['cm_avg7'].iloc[0]\n","    # threshold_config_loaded debe estar disponible (de Celda 1)\n","    threshold_val_from_config = config.get('threshold', 30.0)\n","    active_pipe = None\n","\n","    if pd.notna(cm_avg7_value_for_decision) and cm_avg7_value_for_decision >= threshold_val_from_config:\n","        if pipe_high:\n","            active_pipe = pipe_high\n","            chosen_pipeline_name = \"High\"\n","            print(f\"INFO: Usando Pipeline High (cm_avg7: {cm_avg7_value_for_decision:.2f}€ >= {threshold_val_from_config:.2f}€)\")\n","        elif pipe_low:\n","            active_pipe = pipe_low\n","            chosen_pipeline_name = \"Low (Fallback from High)\"\n","            print(f\"INFO: Pipeline High no disponible, usando Pipeline Low como fallback.\")\n","        else: print(\"ERROR: Pipeline High requerido pero no disponible (pipe_high es None).\")\n","    else:\n","        if pipe_low:\n","            active_pipe = pipe_low\n","            chosen_pipeline_name = \"Low\"\n","            print(f\"INFO: Usando Pipeline Low (cm_avg7: {cm_avg7_value_for_decision:.2f}€ < {threshold_val_from_config:.2f}€ o NaN)\")\n","        elif pipe_high:\n","            active_pipe = pipe_high\n","            chosen_pipeline_name = \"High (Fallback from Low)\"\n","            print(f\"INFO: Pipeline Low no disponible, usando Pipeline High como fallback.\")\n","        else: print(\"ERROR: Pipeline Low requerido pero no disponible (pipe_low es None).\")\n","\n","    if active_pipe:\n","        try:\n","            print(f\"  DEBUG: DataFrame de entrada para pipeline '{chosen_pipeline_name}':\\n{X_new_predict.to_string(index=False)}\")\n","            pred_log = active_pipe.predict(X_new_predict)\n","            pred_numeric = pred_log[0]\n","            # TARGET_IS_LOG_TRANSFORMED debe estar disponible (de Celda 1)\n","            final_prediction = np.expm1(pred_numeric) if TARGET_IS_LOG_TRANSFORMED else pred_numeric\n","            print(f\"  INFO: Predicción cruda (log): {pred_numeric:.4f}, Predicción final (€): {final_prediction:.2f}\")\n","        except Exception as e_pipe:\n","            print(f\"  ERROR en Pipeline '{chosen_pipeline_name}': {e_pipe}\")\n","            import traceback\n","            traceback.print_exc()\n","            final_prediction = None\n","    else:\n","        print(\"ERROR: Ningún pipeline fue seleccionado (active_pipe es None).\")\n","\n","    return final_prediction, chosen_pipeline_name"],"metadata":{"id":"OEXDwKUOg3Mx","executionInfo":{"status":"ok","timestamp":1747155159029,"user_tz":-120,"elapsed":18,"user":{"displayName":"paco jones","userId":"00331554008511532701"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# @title Celda 3: Cargar Datos de Prueba y Ejecutar Predicciones con Pipelines .pkl\n","\n","import pandas as pd # Asegurar que pandas esté importado\n","import numpy as np  # Asegurar que numpy esté importado\n","import random       # Asegurar que random esté importado\n","from sklearn.metrics import mean_absolute_error # Para MAE\n","\n","# --- Definiciones de Columnas Necesarias (Asegúrate que coincidan con Celda 1 o tu entrenamiento) ---\n","NUMERIC_FEATURES_INPUT = ['cm_avg1', 'cm_avg7', 'cm_avg30', 'cm_trendPrice']\n","CATEGORICAL_FEATURES_INPUT = ['rarity', 'supertype', 'subtypes', 'types', 'set_name']\n","INPUT_COLS_FOR_PIPELINES = NUMERIC_FEATURES_INPUT + CATEGORICAL_FEATURES_INPUT\n","# --- Fin Definiciones de Columnas ---\n","\n","# Inicializar df_test_data_full como un DataFrame vacío por si falla la carga\n","df_test_data_full = pd.DataFrame()\n","\n","# --- Cargar tus datos de prueba ---\n","try:\n","    csv_path = '/content/drive/MyDrive/Proyecto API/Final Csv/all_cards_combined_with_tcg.csv'\n","    if os.path.exists(csv_path):\n","        df_test_data_full = pd.read_csv(csv_path)\n","        print(f\"Datos de prueba cargados desde CSV: {len(df_test_data_full)} filas\")\n","\n","        for col in INPUT_COLS_FOR_PIPELINES:\n","            if col not in df_test_data_full.columns:\n","                print(f\"WARNING: Columna '{col}' no encontrada. Rellenando con placeholder.\")\n","                if col in NUMERIC_FEATURES_INPUT: df_test_data_full[col] = 0.0\n","                else: df_test_data_full[col] = 'Unknown_Placeholder'\n","\n","        for col in NUMERIC_FEATURES_INPUT:\n","            if col in df_test_data_full.columns and df_test_data_full[col].isnull().any():\n","                df_test_data_full[col] = pd.to_numeric(df_test_data_full[col], errors='coerce')\n","                median_val = df_test_data_full[col].median(); median_val = 0.0 if pd.isna(median_val) else median_val\n","                df_test_data_full[col] = df_test_data_full[col].fillna(median_val)\n","                print(f\"INFO: NaNs en '{col}' imputados con mediana {median_val:.2f}\")\n","\n","        for col in CATEGORICAL_FEATURES_INPUT:\n","            if col in df_test_data_full.columns:\n","                df_test_data_full[col] = df_test_data_full[col].fillna('Missing_Value').astype(str)\n","    else:\n","        print(f\"ERROR: Archivo CSV de prueba no encontrado: '{csv_path}'\")\n","except FileNotFoundError: print(f\"ERROR: Archivo CSV de prueba no encontrado. Verifica ruta: '{csv_path}'\")\n","except Exception as e_load: print(f\"ERROR al cargar/preprocesar datos CSV: {e_load}\")\n","\n","\n","if not df_test_data_full.empty:\n","    print(f\"\\n--- Ejecutando pruebas de predicción con pipelines .pkl ---\")\n","    num_to_test_run_pkl = min(10, len(df_test_data_full))\n","\n","    if num_to_test_run_pkl > 0:\n","        sample_test_df = pd.DataFrame()\n","        if len(df_test_data_full) >= num_to_test_run_pkl :\n","            sample_test_df = df_test_data_full.sample(n=num_to_test_run_pkl, random_state=42, replace=False)\n","        elif len(df_test_data_full) > 0:\n","             sample_test_df = df_test_data_full.copy(); num_to_test_run_pkl = len(sample_test_df)\n","\n","        if not sample_test_df.empty:\n","            print(f\"Probando con {num_to_test_run_pkl} cartas aleatorias.\")\n","\n","            # Forzar algunas cartas al pipeline High para prueba\n","            # Asegurarse que threshold_config_loaded esté definido (de Celda 1)\n","            if 'threshold_config_loaded' not in locals():\n","                print(\"ERROR CRÍTICO: threshold_config_loaded no definido. Ejecuta la Celda 1.\")\n","                threshold_config_loaded_local_scope = {\"threshold\": 30.0} # Fallback para que no rompa el bucle\n","            else:\n","                threshold_config_loaded_local_scope = threshold_config_loaded\n","\n","\n","            num_to_force_high = min(3, len(sample_test_df))\n","            if num_to_force_high > 0:\n","                print(f\"\\nDEBUG: Forzando cm_avg7 >= threshold para las primeras {num_to_force_high} cartas de la muestra.\")\n","                for i in range(num_to_force_high):\n","                    original_avg7 = sample_test_df.iloc[i]['cm_avg7']\n","                    forced_avg7 = threshold_config_loaded_local_scope.get('threshold', 30.0) + np.random.uniform(5.0, 50.0)\n","                    # Usar .loc para evitar SettingWithCopyWarning\n","                    sample_test_df.loc[sample_test_df.index[i], 'cm_avg7'] = forced_avg7\n","                    print(f\"  Carta {sample_test_df.iloc[i].get('id', 'N/A')}: cm_avg7 cambiado de {original_avg7} a {forced_avg7:.2f}\")\n","\n","            all_test_predictions_run_pkl = []\n","\n","            # Comprobación para asegurar que las variables de la Celda 1 existen\n","            if 'pipeline_high_loaded' not in globals() or 'pipeline_low_loaded' not in globals() or \\\n","               'threshold_config_loaded' not in globals() or '_TARGET_PREDICTED_IS_LOG_TRANSFORMED' not in globals() or \\\n","               'get_prediction_with_lgbm_pipelines' not in globals():\n","                print(\"ERROR CRÍTICO: Una o más variables/funciones (pipeline_high_loaded, pipeline_low_loaded, threshold_config_loaded, _TARGET_PREDICTED_IS_LOG_TRANSFORMED, get_prediction_with_lgbm_pipelines) no están definidas. ¡Asegúrate de ejecutar la Celda 1 y Celda 2 primero!\")\n","            else:\n","                for index, card_row_series in sample_test_df.iterrows():\n","                    input_df_for_pipeline = pd.DataFrame([card_row_series])\n","                    card_name_display = card_row_series.get('name', 'N/A')\n","                    current_price_display = card_row_series.get('cm_averageSellPrice', np.nan)\n","\n","                    print(f\"\\nProcesando carta: {card_row_series.get('id')} ({card_name_display})\")\n","                    cm_avg7_val = card_row_series.get('cm_avg7')\n","                    print(f\"  Datos de entrada para decisión (cm_avg7): {cm_avg7_val if pd.notna(cm_avg7_val) else 'N/A'}\")\n","                    print(f\"  Precio 'target' real de la carta: {current_price_display:.2f}€\" if pd.notna(current_price_display) else \"  Precio 'target' real: N/A\")\n","\n","                    # Llamar a la función definida en Celda 2\n","                    pred_run_pkl, pipeline_used_run_pkl = get_prediction_with_lgbm_pipelines(\n","                        input_df_for_pipeline,\n","                        threshold_config_loaded, # De Celda 1\n","                        pipeline_high_loaded,    # De Celda 1\n","                        pipeline_low_loaded      # De Celda 1\n","                    )\n","                    print(f\"  Pipeline: {pipeline_used_run_pkl}, Pred: {pred_run_pkl:.2f}€\" if pred_run_pkl is not None else f\"  Pipeline: {pipeline_used_run_pkl}, Pred: Falló\")\n","                    if pred_run_pkl is not None:\n","                         all_test_predictions_run_pkl.append({\n","                             'card_id': card_row_series.get('id'), 'name': card_name_display,\n","                             'actual_price': current_price_display, 'predicted_price': pred_run_pkl,\n","                             'pipeline_used': pipeline_used_run_pkl, 'cm_avg7_used': cm_avg7_val\n","                         })\n","\n","            if all_test_predictions_run_pkl:\n","                summary_test_df_run_pkl = pd.DataFrame(all_test_predictions_run_pkl)\n","                print(\"\\n--- Resumen de Pruebas con Pipelines .pkl ---\")\n","                if 'actual_price' in summary_test_df_run_pkl.columns and summary_test_df_run_pkl['actual_price'].notna().any():\n","                    valid_preds = summary_test_df_run_pkl.dropna(subset=['actual_price', 'predicted_price'])\n","                    if not valid_preds.empty:\n","                        mae_test = mean_absolute_error(valid_preds['actual_price'], valid_preds['predicted_price'])\n","                        print(f\"\\nMAE en estas {len(valid_preds)} predicciones de prueba: {mae_test:.2f}€\")\n","                    else: print(\"\\nNo hay suficientes datos válidos para calcular MAE.\")\n","                print(summary_test_df_run_pkl.to_string(index=False))\n","        else: print(\"No se pudieron seleccionar cartas de muestra para probar.\")\n","    else: print(\"No hay datos de prueba para procesar después de cargar el CSV.\")\n","else: print(\"El DataFrame de prueba (df_test_data_full) está vacío. Verifica la carga del CSV.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zMxpvNokC43","executionInfo":{"status":"ok","timestamp":1747155172141,"user_tz":-120,"elapsed":1331,"user":{"displayName":"paco jones","userId":"00331554008511532701"}},"outputId":"328c8b4f-267c-41fa-9428-344e27468587"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Datos de prueba cargados desde CSV: 18876 filas\n","\n","--- Ejecutando pruebas de predicción con pipelines .pkl ---\n","Probando con 10 cartas aleatorias.\n","\n","DEBUG: Forzando cm_avg7 >= threshold para las primeras 3 cartas de la muestra.\n","  Carta base4-87: cm_avg7 cambiado de 2.63 a 51.14\n","  Carta sm7-104: cm_avg7 cambiado de 0.08 a 62.76\n","  Carta bw10-95: cm_avg7 cambiado de 17.91 a 70.78\n","\n","Procesando carta: base4-87 (Pikachu)\n","  Datos de entrada para decisión (cm_avg7): 51.13771956028894\n","  Precio 'target' real de la carta: 2.79€\n","INFO: Usando Pipeline High (cm_avg7: 51.14€ >= 30.00€)\n","  DEBUG: DataFrame de entrada para pipeline 'High':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice rarity supertype subtypes     types   set_name\n","    4.99 51.13772      2.78           3.53 Common   Pokémon    Basic Lightning Base Set 2\n","  INFO: Predicción cruda (log): 3.8492, Predicción final (€): 45.95\n","  Pipeline: High, Pred: 45.95€\n","\n","Procesando carta: sm7-104 (Bagon)\n","  Datos de entrada para decisión (cm_avg7): 62.76352256286418\n","  Precio 'target' real de la carta: 0.09€\n","INFO: Usando Pipeline High (cm_avg7: 62.76€ >= 30.00€)\n","  DEBUG: DataFrame de entrada para pipeline 'High':\n"," cm_avg1   cm_avg7  cm_avg30  cm_trendPrice rarity supertype subtypes  types        set_name\n","     0.1 62.763523       0.1           0.07 Common   Pokémon    Basic Dragon Celestial Storm\n","  INFO: Predicción cruda (log): 3.9898, Predicción final (€): 53.04\n","  Pipeline: High, Pred: 53.04€\n","\n","Procesando carta: bw10-95 (Scoop Up Cyclone)\n","  Datos de entrada para decisión (cm_avg7): 70.77891913117756\n","  Precio 'target' real de la carta: 18.24€\n","INFO: Usando Pipeline High (cm_avg7: 70.78€ >= 30.00€)\n","  DEBUG: DataFrame de entrada para pipeline 'High':\n"," cm_avg1   cm_avg7  cm_avg30  cm_trendPrice   rarity supertype       subtypes   types     set_name\n","    37.0 70.778919      17.4           17.6 Rare ACE   Trainer Item, ACE SPEC Trainer Plasma Blast\n","  INFO: Predicción cruda (log): 3.9888, Predicción final (€): 52.99\n","  Pipeline: High, Pred: 52.99€\n","\n","Procesando carta: ex11-94 (Holon Research Tower)\n","  Datos de entrada para decisión (cm_avg7): 1.33\n","  Precio 'target' real de la carta: 1.36€\n","INFO: Usando Pipeline Low (cm_avg7: 1.33€ < 30.00€ o NaN)\n","  DEBUG: DataFrame de entrada para pipeline 'Low':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice   rarity supertype subtypes   types      set_name\n","    0.88     1.33      1.37           1.01 Uncommon   Trainer  Stadium Trainer Delta Species\n","  INFO: Predicción cruda (log): 0.8927, Predicción final (€): 1.44\n","  Pipeline: Low, Pred: 1.44€\n","\n","Procesando carta: sv3-111 (Drilbur)\n","  Datos de entrada para decisión (cm_avg7): 0.04\n","  Precio 'target' real de la carta: 0.04€\n","INFO: Usando Pipeline Low (cm_avg7: 0.04€ < 30.00€ o NaN)\n","  DEBUG: DataFrame de entrada para pipeline 'Low':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice rarity supertype subtypes    types        set_name\n","    0.24     0.04      0.04           0.06 Common   Pokémon    Basic Fighting Obsidian Flames\n","  INFO: Predicción cruda (log): 0.0392, Predicción final (€): 0.04\n","  Pipeline: Low, Pred: 0.04€\n","\n","Procesando carta: swsh9-110 (Axew)\n","  Datos de entrada para decisión (cm_avg7): 0.03\n","  Precio 'target' real de la carta: 0.03€\n","INFO: Usando Pipeline Low (cm_avg7: 0.03€ < 30.00€ o NaN)\n","  DEBUG: DataFrame de entrada para pipeline 'Low':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice rarity supertype subtypes  types        set_name\n","    0.03     0.03      0.03           0.03 Common   Pokémon    Basic Dragon Brilliant Stars\n","  INFO: Predicción cruda (log): 0.0296, Predicción final (€): 0.03\n","  Pipeline: Low, Pred: 0.03€\n","\n","Procesando carta: xyp-XY59 (Salamence)\n","  Datos de entrada para decisión (cm_avg7): 8.15\n","  Precio 'target' real de la carta: 8.26€\n","INFO: Usando Pipeline Low (cm_avg7: 8.15€ < 30.00€ o NaN)\n","  DEBUG: DataFrame de entrada para pipeline 'Low':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice rarity supertype subtypes  types             set_name\n","    10.0     8.15      7.23           8.12  Promo   Pokémon  Stage 2 Dragon XY Black Star Promos\n","  INFO: Predicción cruda (log): 2.1516, Predicción final (€): 7.60\n","  Pipeline: Low, Pred: 7.60€\n","\n","Procesando carta: smp-SM13 (Oranguru)\n","  Datos de entrada para decisión (cm_avg7): 17.46\n","  Precio 'target' real de la carta: 0.00€\n","INFO: Usando Pipeline Low (cm_avg7: 17.46€ < 30.00€ o NaN)\n","  DEBUG: DataFrame de entrada para pipeline 'Low':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice rarity supertype subtypes     types             set_name\n","    15.0    17.46     16.35          15.31  Promo   Pokémon    Basic Colorless SM Black Star Promos\n","  INFO: Predicción cruda (log): 2.8420, Predicción final (€): 16.15\n","  Pipeline: Low, Pred: 16.15€\n","\n","Procesando carta: sm11-155 (Fraxure)\n","  Datos de entrada para decisión (cm_avg7): 0.13\n","  Precio 'target' real de la carta: 0.12€\n","INFO: Usando Pipeline Low (cm_avg7: 0.13€ < 30.00€ o NaN)\n","  DEBUG: DataFrame de entrada para pipeline 'Low':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice   rarity supertype subtypes  types      set_name\n","    0.07     0.13      0.11           0.13 Uncommon   Pokémon  Stage 1 Dragon Unified Minds\n","  INFO: Predicción cruda (log): 0.1078, Predicción final (€): 0.11\n","  Pipeline: Low, Pred: 0.11€\n","\n","Procesando carta: swsh1-118 (Galarian Linoone)\n","  Datos de entrada para decisión (cm_avg7): 0.07\n","  Precio 'target' real de la carta: 0.07€\n","INFO: Usando Pipeline Low (cm_avg7: 0.07€ < 30.00€ o NaN)\n","  DEBUG: DataFrame de entrada para pipeline 'Low':\n"," cm_avg1  cm_avg7  cm_avg30  cm_trendPrice   rarity supertype subtypes    types       set_name\n","    0.15     0.07      0.08           0.07 Uncommon   Pokémon  Stage 1 Darkness Sword & Shield\n","  INFO: Predicción cruda (log): 0.0748, Predicción final (€): 0.08\n","  Pipeline: Low, Pred: 0.08€\n","\n","--- Resumen de Pruebas con Pipelines .pkl ---\n","\n","MAE en estas 10 predicciones de prueba: 14.78€\n","  card_id                 name  actual_price  predicted_price pipeline_used  cm_avg7_used\n"," base4-87              Pikachu          2.79        45.953427          High     51.137720\n","  sm7-104                Bagon          0.09        53.041693          High     62.763523\n","  bw10-95     Scoop Up Cyclone         18.24        52.991139          High     70.778919\n","  ex11-94 Holon Research Tower          1.36         1.441658           Low      1.330000\n","  sv3-111              Drilbur          0.04         0.040000           Low      0.040000\n","swsh9-110                 Axew          0.03         0.030020           Low      0.030000\n"," xyp-XY59            Salamence          8.26         7.598460           Low      8.150000\n"," smp-SM13             Oranguru          0.00        16.150502           Low     17.460000\n"," sm11-155              Fraxure          0.12         0.113854           Low      0.130000\n","swsh1-118     Galarian Linoone          0.07         0.077717           Low      0.070000\n"]}]}]}